{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 6 - Différentes utilisations dumachine learning avec Python (4ème partie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Le deep learning avec Keras\n",
    "\n",
    "### 6.7.2 Principe d’un réseau de neurone et première utilisation avec Keras\n",
    "\n",
    "Le package Keras que nous avons installé est basé sur une structure extrêmement\n",
    "simple à mettre en oeuvre. On commence par définir le type de réseau utilisé. Dans\n",
    "cet ouvrage, il s’agira de réseaux séquentiels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous prenons les données sur les télécommunications que nous avons utilisées\n",
    "précédemment, nous pouvons simplement utiliser Keras pour créer un réseau de neurones assez évolué (on suppose ici que les données ont été préparées comme\n",
    "dans la première partie de ce chapitre avec Scikit-Learn) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s4d-asus-14\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv(\"../data/x_telecom.csv\",index_col=0)\n",
    "y=pd.read_csv(\"../data/y_telecom.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# on sépare nos données en apprentissage/validation avec Scikit-Learn\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on crée le modèle\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ajoute des couches avec des fonctions d’activation\n",
    "model.add(Dense(50, input_shape=(22,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "# cette couche permet de normaliser les données\n",
    "model.add(BatchNormalization())\n",
    "# cette couche va faire en sorte d’éviter l’overfitting\n",
    "model.add(Dropout(0.1))\n",
    "# on ajoute un autre groupe de couches\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "# on ajoute la couche de sortie\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on définit la fonction de perte et la fonction d’optiimsation\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2666/2666 [==============================] - 1s 289us/step - loss: 0.7754 - acc: 0.4839\n",
      "Epoch 2/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.6802 - acc: 0.5716\n",
      "Epoch 3/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.6475 - acc: 0.6302\n",
      "Epoch 4/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.6120 - acc: 0.7082\n",
      "Epoch 5/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.5747 - acc: 0.7536\n",
      "Epoch 6/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.5478 - acc: 0.7907\n",
      "Epoch 7/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.5267 - acc: 0.8087\n",
      "Epoch 8/100\n",
      "2666/2666 [==============================] - 0s 20us/step - loss: 0.4973 - acc: 0.8248\n",
      "Epoch 9/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.4713 - acc: 0.8428\n",
      "Epoch 10/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.4512 - acc: 0.8466\n",
      "Epoch 11/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.4364 - acc: 0.8563\n",
      "Epoch 12/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.4131 - acc: 0.8631\n",
      "Epoch 13/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.4039 - acc: 0.8691\n",
      "Epoch 14/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3941 - acc: 0.8695\n",
      "Epoch 15/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3865 - acc: 0.8747\n",
      "Epoch 16/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3709 - acc: 0.8785\n",
      "Epoch 17/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3672 - acc: 0.8785\n",
      "Epoch 18/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3617 - acc: 0.8815\n",
      "Epoch 19/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3527 - acc: 0.8792\n",
      "Epoch 20/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3531 - acc: 0.8807\n",
      "Epoch 21/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3460 - acc: 0.8875\n",
      "Epoch 22/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3403 - acc: 0.8845\n",
      "Epoch 23/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3464 - acc: 0.8852\n",
      "Epoch 24/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.3395 - acc: 0.8878\n",
      "Epoch 25/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3394 - acc: 0.8822\n",
      "Epoch 26/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3462 - acc: 0.8845\n",
      "Epoch 27/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3355 - acc: 0.8901\n",
      "Epoch 28/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3349 - acc: 0.8890\n",
      "Epoch 29/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.3323 - acc: 0.8878\n",
      "Epoch 30/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.3419 - acc: 0.8841\n",
      "Epoch 31/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3324 - acc: 0.8916\n",
      "Epoch 32/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3337 - acc: 0.8875\n",
      "Epoch 33/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3312 - acc: 0.8890\n",
      "Epoch 34/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3366 - acc: 0.8901\n",
      "Epoch 35/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3321 - acc: 0.8871\n",
      "Epoch 36/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3277 - acc: 0.8908\n",
      "Epoch 37/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3300 - acc: 0.8890\n",
      "Epoch 38/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3263 - acc: 0.8920\n",
      "Epoch 39/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3143 - acc: 0.8957\n",
      "Epoch 40/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3271 - acc: 0.8871\n",
      "Epoch 41/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3241 - acc: 0.8912\n",
      "Epoch 42/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3137 - acc: 0.8905\n",
      "Epoch 43/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3271 - acc: 0.8867\n",
      "Epoch 44/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3181 - acc: 0.8920\n",
      "Epoch 45/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3093 - acc: 0.8953\n",
      "Epoch 46/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.3136 - acc: 0.8942\n",
      "Epoch 47/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.3083 - acc: 0.8950\n",
      "Epoch 48/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3061 - acc: 0.8968\n",
      "Epoch 49/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3109 - acc: 0.8957\n",
      "Epoch 50/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3186 - acc: 0.8920\n",
      "Epoch 51/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3139 - acc: 0.8905\n",
      "Epoch 52/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3073 - acc: 0.8957\n",
      "Epoch 53/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3007 - acc: 0.8965\n",
      "Epoch 54/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.3069 - acc: 0.8935\n",
      "Epoch 55/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3035 - acc: 0.8927\n",
      "Epoch 56/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.2938 - acc: 0.8972\n",
      "Epoch 57/100\n",
      "2666/2666 [==============================] - 0s 19us/step - loss: 0.3007 - acc: 0.8995\n",
      "Epoch 58/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.3072 - acc: 0.8957\n",
      "Epoch 59/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2984 - acc: 0.8968\n",
      "Epoch 60/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3011 - acc: 0.8935\n",
      "Epoch 61/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2986 - acc: 0.8968\n",
      "Epoch 62/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.3019 - acc: 0.8931\n",
      "Epoch 63/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2829 - acc: 0.8972\n",
      "Epoch 64/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2986 - acc: 0.8938\n",
      "Epoch 65/100\n",
      "2666/2666 [==============================] - 0s 15us/step - loss: 0.2891 - acc: 0.8950\n",
      "Epoch 66/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2993 - acc: 0.8968\n",
      "Epoch 67/100\n",
      "2666/2666 [==============================] - 0s 15us/step - loss: 0.3026 - acc: 0.8901\n",
      "Epoch 68/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.2891 - acc: 0.8965\n",
      "Epoch 69/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.2984 - acc: 0.8923\n",
      "Epoch 70/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.2872 - acc: 0.8931\n",
      "Epoch 71/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.2940 - acc: 0.8923\n",
      "Epoch 72/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2859 - acc: 0.8983\n",
      "Epoch 73/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2871 - acc: 0.8953\n",
      "Epoch 74/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.2864 - acc: 0.8998\n",
      "Epoch 75/100\n",
      "2666/2666 [==============================] - 0s 15us/step - loss: 0.2863 - acc: 0.8942\n",
      "Epoch 76/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2810 - acc: 0.8950\n",
      "Epoch 77/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2810 - acc: 0.8946\n",
      "Epoch 78/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2789 - acc: 0.8946\n",
      "Epoch 79/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2843 - acc: 0.8968\n",
      "Epoch 80/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2779 - acc: 0.8957\n",
      "Epoch 81/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2877 - acc: 0.8976\n",
      "Epoch 82/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2736 - acc: 0.9025\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2857 - acc: 0.8905\n",
      "Epoch 84/100\n",
      "2666/2666 [==============================] - 0s 18us/step - loss: 0.2733 - acc: 0.8976\n",
      "Epoch 85/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.2792 - acc: 0.9014\n",
      "Epoch 86/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.2777 - acc: 0.8935\n",
      "Epoch 87/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.2899 - acc: 0.8890\n",
      "Epoch 88/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.2770 - acc: 0.8965\n",
      "Epoch 89/100\n",
      "2666/2666 [==============================] - 0s 15us/step - loss: 0.2736 - acc: 0.8946\n",
      "Epoch 90/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2720 - acc: 0.8950\n",
      "Epoch 91/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2715 - acc: 0.8965\n",
      "Epoch 92/100\n",
      "2666/2666 [==============================] - 0s 15us/step - loss: 0.2712 - acc: 0.8987\n",
      "Epoch 93/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2660 - acc: 0.9006\n",
      "Epoch 94/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2782 - acc: 0.8953\n",
      "Epoch 95/100\n",
      "2666/2666 [==============================] - 0s 17us/step - loss: 0.2688 - acc: 0.8972\n",
      "Epoch 96/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2557 - acc: 0.9051\n",
      "Epoch 97/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2672 - acc: 0.8968\n",
      "Epoch 98/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2652 - acc: 0.9021\n",
      "Epoch 99/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2848 - acc: 0.8968\n",
      "Epoch 100/100\n",
      "2666/2666 [==============================] - 0s 16us/step - loss: 0.2680 - acc: 0.9029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13b3b6d5b70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on ajuste le modèle\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC pour RN : 0.8907917293496135\n"
     ]
    }
   ],
   "source": [
    "# on calcule l’AUC pour les données de validation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC pour RN :\", roc_auc_score(y_test,\n",
    "                                     model.predict_proba(x_test, \n",
    "                                                         verbose=0).reshape(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les réseaux de neurones sont des méthodes extrêmement efficaces à condition\n",
    "de bien les paramétrer ce qui peut s‘avérer très difficile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.3 Le deep learning et les réseaux de neurones à convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant travailler sur des images. On prendra les données fashion-mnist :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des données\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# les données sont transformées pour passer sous un format d’image\n",
    "# standard avec des valeurs entre 0 et 1\n",
    "x_train = (x_train/255).reshape(x_train.shape[0], 28, 28,1)\n",
    "x_test = (x_test/255).reshape(x_test.shape[0], 28, 28,1)\n",
    "\n",
    "# passage à 10 colonnes pour y(une par modalité)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction du modèle\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation du modèle\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustement du modèle\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation du modèle\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons appliqué deux couches de convolutions à 32 neurones avec une taille\n",
    "de fenêtre de 3 par 3. Puis une couche de pooling avec une réduction sur des fenêtres\n",
    "de 2 par 2. Nous obtenons les résultats suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtention de l’accuracy sur les données de validation\n",
    "print(\"Pourcentage de bien classées :\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu’on est au-delà de 92 % bien classés sur l’échantillon de validation.\n",
    "Dans notre cas, on a utilisé des images directement dans le package Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Généralement, les images sont stockées dans des répertoires différents. Keras\n",
    "possède de nombreux outils pour charger ces images, on peut par exemple utiliser\n",
    "ImageDataGenerator :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# on définit un générateur qui pourrait modifier nos images\n",
    "# (dans ce cas on passe en float 0 à 1)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# on définit le dossier dans lequel se trouve les images\n",
    "train_generator = train_datagen.flow_from_directory('../data/train',target_size=(150, 150),\n",
    "                                                    batch_size=32,class_mode='binary')\n",
    "# on définit le dossier dans lequel se trouve les images\n",
    "validation_generator = test_datagen.flow_from_directory('../data/validation',\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ajuste notre modèle de deep learning avec les images\n",
    "# de nos dossiers\n",
    "model.fit_generator(train_generator,epochs=50,\n",
    "                    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez maintenant tous les outils pour vous lancer dans la construction de\n",
    "réseaux de deep learning avec Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.4 Aller plus loin : génération de features, transfer learning, RN, GAN …\n",
    "On charge facilement un modèle avec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.resnet50 import decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on utilise le modèle ResNet50\n",
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère une nouvelle image\n",
    "img_path = '../data/elephant.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on applique le modèle\n",
    "preds = model.predict(x)\n",
    "print('Prédit (classe/ %):', decode_predictions(preds, top=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient donc un résultat à partir du modèle chargé. On pourra utiliser ce modèle\n",
    "et ses poids dans des couches intermédiaires de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cas, on a chargé un modèle et on lui a fourni une photographie d’éléphant.\n",
    "Le modèle considère que c’est un éléphant d’Afrique à 87%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons effectué un panorama approfondi de l’utilisation de Python\n",
    "pour faire du machine learning, du deep learning et du traitement des\n",
    "données textuelles. Python ressort comme un langage adapté à toutes\n",
    "ces approches et un outil indispensable pour le data scientist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
